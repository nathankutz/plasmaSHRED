{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHRED for ROMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first randomly select 3 sensor locations and set the trajectory length (lags) to 52, which is hyperparameter tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "u_total = np.load('u_total.npy')\n",
    "v_total = np.load('v_total.npy')\n",
    "s_total = np.load('s_total.npy')\n",
    "\n",
    "plasma_data = sio.loadmat('data14fields/ne')\n",
    "utemp = plasma_data['Data']\n",
    "X = utemp - np.mean(utemp, axis=0)\n",
    "Xnorm= np.max(np.abs(X))\n",
    "X = X/Xnorm\n",
    "\n",
    "\n",
    "print(u_total.shape)\n",
    "print(v_total.shape)\n",
    "print(s_total.shape)\n",
    "print(X.shape)\n",
    "n2 = (X).shape[0]\n",
    "print(n2)\n",
    "m2 = s_total.shape[1]  # svd modes used\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processdata import load_data\n",
    "from processdata import TimeSeriesDataset\n",
    "import models\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "num_sensors = 3 \n",
    "lags = 52\n",
    "\n",
    "nx = 257\n",
    "ny = 256\n",
    "\n",
    "load_X = v_total.T\n",
    "\n",
    "sensor_locations_ne = np.random.choice(n2, size=num_sensors, replace=False)\n",
    "sensor_locations = [0, 1, 2]\n",
    "\n",
    "load_X = np.hstack((X[sensor_locations_ne,:].T,load_X))\n",
    "np.save('load_X.npy', load_X)\n",
    "\n",
    "plt.imshow(load_X)\n",
    "n = (load_X).shape[0]\n",
    "m = (load_X).shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "print(sensor_locations_ne)\n",
    "mask = np.zeros(n2)\n",
    "mask[sensor_locations_ne[0]]=1\n",
    "mask[sensor_locations_ne[1]]=1\n",
    "mask[sensor_locations_ne[2]]=1\n",
    "\n",
    "mask2 = mask.reshape((nx,ny))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(25, 20))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "plt.imshow(mask2, cmap='gray')\n",
    "\n",
    "plt.savefig('measure.pdf')\n",
    "\n",
    "#fig = plt.figure(figsize=(15, 10))\n",
    "#x = fig.add_subplot(2, 1, 2)\n",
    "#plt.plot(X[sensor_locations_ne,:].T)\n",
    "\n",
    "#plt.savefig('sensing.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now select indices to divide the data into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECONSTRUCTION MODE\n",
    "train_indices = np.random.choice(n - lags, size=500, replace=False)\n",
    "mask = np.ones(n - lags)\n",
    "mask[train_indices] = 0\n",
    "valid_test_indices = np.arange(0, n - lags)[np.where(mask!=0)[0]]\n",
    "valid_indices = valid_test_indices[::2]\n",
    "test_indices = valid_test_indices[1::2]\n",
    "\n",
    "# FORECASTING MODE\n",
    "# train_indices = np.arange(0, int(n*0.85))\n",
    "# valid_indices = np.arange(int(n*0.85), int(n*0.85) + 20)\n",
    "# test_indices = np.arange(int(n*0.85) + 20, n - lags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn's MinMaxScaler is used to preprocess the data for training and we generate input/output pairs for the training, validation, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "sc = sc.fit(load_X[train_indices])\n",
    "transformed_X = sc.transform(load_X)\n",
    "\n",
    "### Generate input sequences to a SHRED model\n",
    "all_data_in = np.zeros((n - lags, lags, num_sensors))\n",
    "for i in range(len(all_data_in)):\n",
    "    all_data_in[i] = transformed_X[i:i+lags, sensor_locations]\n",
    "\n",
    "### Generate training validation and test datasets both for reconstruction of states and forecasting sensors\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_data_in = torch.tensor(all_data_in[train_indices], dtype=torch.float32).to(device)\n",
    "valid_data_in = torch.tensor(all_data_in[valid_indices], dtype=torch.float32).to(device)\n",
    "test_data_in = torch.tensor(all_data_in[test_indices], dtype=torch.float32).to(device)\n",
    "\n",
    "### -1 to have output be at the same time as final sensor measurements\n",
    "train_data_out = torch.tensor(transformed_X[train_indices + lags - 1], dtype=torch.float32).to(device)\n",
    "valid_data_out = torch.tensor(transformed_X[valid_indices + lags - 1], dtype=torch.float32).to(device)\n",
    "test_data_out = torch.tensor(transformed_X[test_indices + lags - 1], dtype=torch.float32).to(device)\n",
    "\n",
    "train_dataset = TimeSeriesDataset(train_data_in, train_data_out)\n",
    "valid_dataset = TimeSeriesDataset(valid_data_in, valid_data_out)\n",
    "test_dataset = TimeSeriesDataset(test_data_in, test_data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model using the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shred = models.SHRED(num_sensors, m, hidden_size=64, hidden_layers=2, l1=350, l2=400, dropout=0.1).to(device)\n",
    "validation_errors = models.fit(shred, train_dataset, valid_dataset, batch_size=64, num_epochs=3000, lr=1e-3, verbose=True, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate reconstructions from the test set and print mean square error compared to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recons = sc.inverse_transform(shred(test_dataset.X).detach().cpu().numpy())\n",
    "test_ground_truth = sc.inverse_transform(test_dataset.Y.detach().cpu().numpy())\n",
    "print(np.linalg.norm(test_recons - test_ground_truth) / np.linalg.norm(test_ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(2, 3, 1)\n",
    "plt.plot(test_recons[10])\n",
    "ax = fig.add_subplot(2, 3, 4)\n",
    "plt.plot(test_ground_truth[10])\n",
    "ax = fig.add_subplot(2, 3, 2)\n",
    "plt.plot(test_recons[50])\n",
    "ax = fig.add_subplot(2, 3, 5)\n",
    "plt.plot(test_ground_truth[50])\n",
    "ax = fig.add_subplot(2, 3, 3)\n",
    "plt.plot(test_recons[150])\n",
    "ax = fig.add_subplot(2, 3, 6)\n",
    "plt.plot(test_ground_truth[150])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "plt.imshow(test_recons[:,3:])\n",
    "ax = fig.add_subplot(2, 1, 2)\n",
    "plt.imshow(test_ground_truth[:,3:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_ground_truth.shape)\n",
    "print(test_recons.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "x=test_recons[:,[40]]\n",
    "plt.plot(x)\n",
    "ax = fig.add_subplot(2, 1, 2)\n",
    "x=test_ground_truth[:,[40]]\n",
    "plt.plot(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "x=test_recons[:,[140]]\n",
    "plt.plot(x)\n",
    "ax = fig.add_subplot(2, 1, 2)\n",
    "x=test_ground_truth[:,[140]]\n",
    "plt.plot(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 20))\n",
    "mpoint = 20000\n",
    "\n",
    "for jj in range(14):\n",
    "    ax = fig.add_subplot(7, 2, jj+1)\n",
    "    upca = u_total[:, jj*m2:(jj+1)*m2]\n",
    "    spca = s_total[jj, :]\n",
    "    vpca1 = test_ground_truth[:, jj*m2+3:(jj+1)*m2+3]\n",
    "    vpca2 = test_recons[:,jj*m2+3:(jj+1)*m2+3]\n",
    "    \n",
    "    u1svd = upca @ np.diag(spca) @ vpca1.T\n",
    "    u2svd = upca @ np.diag(spca) @ vpca2.T\n",
    "    \n",
    "    plt.plot(u1svd[mpoint,100:400], color='gray')\n",
    "    plt.plot(u2svd[mpoint,100:400])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.axis('off')\n",
    "\n",
    "   # ax.set_title(f\"Plot {jj+1}\")\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig('timeseries.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "loop1=[0,1,2,3,4,5,6]\n",
    "loop2=[7,8,9,10,11,12,13]\n",
    "\n",
    "for jj in loop1:\n",
    "    ax = fig.add_subplot(1, 7, jj+1)\n",
    "\n",
    "    upca = u_total[:, jj*m2:(jj+1)*m2]\n",
    "    spca = s_total[jj, :]\n",
    "    vpca1 = test_ground_truth[:, jj*m2+3:(jj+1)*m2+3]\n",
    "\n",
    "    u1svd = upca @ np.diag(spca) @ vpca1.T\n",
    "    snap_true = u1svd[0:nx*ny, j].reshape((nx, ny)).T\n",
    "    ax.imshow(snap_true,cmap='RdBu_r', interpolation='bilinear')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.savefig('comp1.pdf')\n",
    "plt.show()    \n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for jj in loop1:\n",
    "    ax = fig.add_subplot(1, 7, jj+1)\n",
    "    upca = u_total[:, jj*m2:(jj+1)*m2]\n",
    "    spca = s_total[jj, :]\n",
    "    #vpca1 = test_ground_truth[:, jj+3:jj+m2+3]\n",
    "    vpca2 = test_recons[:,jj*m2+3:(jj+1)*m2+3]\n",
    "\n",
    "    #u1svd = upca @ np.diag(spca) @ vpca1.T\n",
    "    u2svd = upca @ np.diag(spca) @ vpca2.T\n",
    "    \n",
    "    #snap_true = u1svd[0:nx*ny, j].reshape((nx, ny))\n",
    "    snap_test = u2svd[0:nx*ny,j].reshape((nx,ny)).T\n",
    "    ax.imshow(snap_test,cmap='RdBu_r', interpolation='bilinear')\n",
    "\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.savefig('comp2.pdf')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for jj in loop2:\n",
    "    ax = fig.add_subplot(1, 7, jj-6)\n",
    "\n",
    "    upca = u_total[:, jj*m2:(jj+1)*m2]\n",
    "    spca = s_total[jj, :]\n",
    "    vpca1 = test_ground_truth[:, jj*m2+3:(jj+1)*m2+3]\n",
    "\n",
    "    u1svd = upca @ np.diag(spca) @ vpca1.T\n",
    "    snap_true = u1svd[0:nx*ny, j].reshape((nx, ny)).T\n",
    "    ax.imshow(snap_true,cmap='RdBu_r', interpolation='bilinear')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.savefig('comp3.pdf')\n",
    "plt.show()    \n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for jj in loop2:\n",
    "    ax = fig.add_subplot(1, 7, jj-6)\n",
    "    upca = u_total[:, jj*m2:(jj+1)*m2]\n",
    "    spca = s_total[jj, :]\n",
    "    #vpca1 = test_ground_truth[:, jj+3:jj+m2+3]\n",
    "    vpca2 = test_recons[:, jj*m2+3:(jj+1)*m2+3]\n",
    "\n",
    "    #u1svd = upca @ np.diag(spca) @ vpca1.T\n",
    "    u2svd = upca @ np.diag(spca) @ vpca2.T\n",
    "    \n",
    "    #snap_true = u1svd[0:nx*ny, j].reshape((nx, ny))\n",
    "    snap_test = u2svd[0:nx*ny,j].reshape((nx,ny)).T\n",
    "    ax.imshow(snap_test,cmap='RdBu_r', interpolation='bilinear')\n",
    "\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.savefig('comp4.pdf')\n",
    "plt.show()    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "071f83251836d5bb3918d2af6501aef1a588d685a567aa45f470f25864dd9495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
